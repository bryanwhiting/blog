---
title: Prompt techniques 
description: |
  Open AI strategies 
date: 2023-12-15
categories: [ai]
draft: false
---

![](photo.jpeg) 

# How to Prompt Engineer

::: callout-note
## TL;DR: [Prompt Engineering](https://platform.openai.com/docs/guides/prompt-engineering/prompt-engineering)
:::

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Open AI released a great Prompt Engineering guide (link in comments). <br><br>Here is a summary of their 6 strategies for getting better results when prompting GPT-4 <a href="https://t.co/QiBASsbOHD">pic.twitter.com/QiBASsbOHD</a></p>&mdash; MindBranches (@MindBranches) <a href="https://twitter.com/MindBranches/status/1735497957842047056?ref_src=twsrc%5Etfw">December 15, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

The summary above is from here: 

[Prompt Engineering](https://platform.openai.com/docs/guides/prompt-engineering/prompt-engineering)
 

# Takeaways

If prompt engineering is the future of coding, then coding is going to change from a deterministic, imperative experience to a stochastic one. That seems odd. 95% chance your output code will do what you want it to do, with a 5% change it does something drastically wrong. How do you unit test that?

