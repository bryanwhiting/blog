---
title: Machine Learning Q and AI
date: 2024-04-16 20:26:32
created: 2024-04-16 20:26:32
categories:
  - book-review
draft: false
author: Sebastian Raschka
book-year: 2024
book-time: 0
date-start: 2024-04-16 20:26:32
date-finished: 2024-04-16 20:26:32
pct-complete:
---

2024-05-16

Chapter 5

- Reduce overfitting by getting more quality data 
- Augment your data (Mixups) to prevent overfitting. 

2024-04-30

- Lottery ticket hypothesis: take a full model and prune it down to get the same performance. Reweight. Rebalance. Simplify. Iterate. The multiple things. 

2024-04-29

- when doing image classification you 1) label the data and 2) create batches of support sets and query sets, 3) training episodes where you update and reweight the embedding a best classify the query set classes. 

2024-04-18

Chapter 2

- you can unsupervise learn something by adding noise to the truth and minimizing the distance in the embeddings between truth and noisy truth and maximize distance from something else. 
- Transfer learning: one general model, then update the target variable and dataset for a smaller model. 


2024-04-17 



![Machine Learning Q and AI](../img/book-machine-learning-q-and-ai.jpeg){.preview-image}
